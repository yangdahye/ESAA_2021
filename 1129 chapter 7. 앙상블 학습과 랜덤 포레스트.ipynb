{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chapter 7. 앙상블 학습과 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 투표 기반 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.896\n",
      "RandomForestClassifier 0.944\n",
      "SVC 0.928\n",
      "VotingClassifier 0.928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 배깅과 페이스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 사이킷런의 배깅과 페이스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 oob 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00529101, 0.99470899],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98843931, 0.01156069],\n",
       "       [0.6043956 , 0.3956044 ],\n",
       "       [0.41340782, 0.58659218],\n",
       "       [1.        , 0.        ],\n",
       "       [0.43859649, 0.56140351],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94413408, 0.05586592],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80555556, 0.19444444],\n",
       "       [0.578125  , 0.421875  ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.70833333, 0.29166667],\n",
       "       [0.15642458, 0.84357542],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93684211, 0.06315789],\n",
       "       [1.        , 0.        ],\n",
       "       [0.66666667, 0.33333333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03571429, 0.96428571],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [0.        , 1.        ],\n",
       "       [0.37765957, 0.62234043],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02298851, 0.97701149],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.        , 1.        ],\n",
       "       [0.83253589, 0.16746411],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [0.29943503, 0.70056497],\n",
       "       [0.65517241, 0.34482759],\n",
       "       [0.01829268, 0.98170732],\n",
       "       [1.        , 0.        ],\n",
       "       [0.13953488, 0.86046512],\n",
       "       [0.45226131, 0.54773869],\n",
       "       [0.        , 1.        ],\n",
       "       [0.59296482, 0.40703518],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02702703, 0.97297297],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03428571, 0.96571429],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.98514851, 0.01485149],\n",
       "       [0.43093923, 0.56906077],\n",
       "       [0.65644172, 0.34355828],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95454545, 0.04545455],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [0.953125  , 0.046875  ],\n",
       "       [0.95402299, 0.04597701],\n",
       "       [0.96551724, 0.03448276],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.91099476, 0.08900524],\n",
       "       [0.19689119, 0.80310881],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94764398, 0.05235602],\n",
       "       [0.97837838, 0.02162162],\n",
       "       [0.11320755, 0.88679245],\n",
       "       [1.        , 0.        ],\n",
       "       [0.88819876, 0.11180124],\n",
       "       [0.        , 1.        ],\n",
       "       [0.4137931 , 0.5862069 ],\n",
       "       [0.81865285, 0.18134715],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93989071, 0.06010929],\n",
       "       [0.97175141, 0.02824859],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.98947368, 0.01052632],\n",
       "       [0.11731844, 0.88268156],\n",
       "       [0.01704545, 0.98295455],\n",
       "       [0.18781726, 0.81218274],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8150289 , 0.1849711 ],\n",
       "       [0.93548387, 0.06451613],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18877551, 0.81122449],\n",
       "       [0.73888889, 0.26111111],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62944162, 0.37055838],\n",
       "       [0.01604278, 0.98395722],\n",
       "       [0.01129944, 0.98870056],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96666667, 0.03333333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98974359, 0.01025641],\n",
       "       [0.98918919, 0.01081081],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [0.98285714, 0.01714286],\n",
       "       [0.08290155, 0.91709845],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.97159091, 0.02840909],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [0.91878173, 0.08121827],\n",
       "       [0.16363636, 0.83636364],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.99481865, 0.00518135],\n",
       "       [0.91011236, 0.08988764],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98314607, 0.01685393],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [0.71875   , 0.28125   ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.2611465 , 0.7388535 ],\n",
       "       [0.21134021, 0.78865979],\n",
       "       [0.        , 1.        ],\n",
       "       [0.82758621, 0.17241379],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.24137931, 0.75862069],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9744898 , 0.0255102 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.85310734, 0.14689266],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06282723, 0.93717277],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.98245614, 0.01754386],\n",
       "       [0.52849741, 0.47150259],\n",
       "       [0.09782609, 0.90217391],\n",
       "       [0.00609756, 0.99390244],\n",
       "       [0.        , 1.        ],\n",
       "       [0.59677419, 0.40322581],\n",
       "       [0.80701754, 0.19298246],\n",
       "       [0.98412698, 0.01587302],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48913043, 0.51086957],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.        , 1.        ],\n",
       "       [0.55232558, 0.44767442],\n",
       "       [1.        , 0.        ],\n",
       "       [0.39622642, 0.60377358],\n",
       "       [0.85167464, 0.14832536],\n",
       "       [0.98214286, 0.01785714],\n",
       "       [0.        , 1.        ],\n",
       "       [0.84883721, 0.15116279],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99418605, 0.00581395],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06557377, 0.93442623],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98830409, 0.01169591],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9760479 , 0.0239521 ],\n",
       "       [0.14035088, 0.85964912],\n",
       "       [0.21182266, 0.78817734],\n",
       "       [0.43169399, 0.56830601],\n",
       "       [0.12209302, 0.87790698],\n",
       "       [0.33157895, 0.66842105],\n",
       "       [0.        , 1.        ],\n",
       "       [0.88135593, 0.11864407],\n",
       "       [0.10552764, 0.89447236],\n",
       "       [0.        , 1.        ],\n",
       "       [0.88648649, 0.11351351],\n",
       "       [0.95698925, 0.04301075],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02857143, 0.97142857],\n",
       "       [0.90963855, 0.09036145],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.49152542, 0.50847458],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.14948454, 0.85051546],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.12690355, 0.87309645],\n",
       "       [0.02222222, 0.97777778],\n",
       "       [0.59776536, 0.40223464],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [0.15228426, 0.84771574],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1005291 , 0.8994709 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08928571, 0.91071429],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95977011, 0.04022989],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98941799, 0.01058201],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9035533 , 0.0964467 ],\n",
       "       [0.01530612, 0.98469388],\n",
       "       [0.05586592, 0.94413408],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97740113, 0.02259887],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97740113, 0.02259887],\n",
       "       [0.86708861, 0.13291139],\n",
       "       [0.82474227, 0.17525773],\n",
       "       [0.91666667, 0.08333333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94179894, 0.05820106],\n",
       "       [0.73170732, 0.26829268],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03448276, 0.96551724],\n",
       "       [0.02793296, 0.97206704],\n",
       "       [0.77647059, 0.22352941],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91959799, 0.08040201],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75531915, 0.24468085],\n",
       "       [0.03797468, 0.96202532],\n",
       "       [0.02645503, 0.97354497],\n",
       "       [0.68786127, 0.31213873],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03141361, 0.96858639],\n",
       "       [0.        , 1.        ],\n",
       "       [0.20555556, 0.79444444],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97191011, 0.02808989],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00512821, 0.99487179],\n",
       "       [0.31693989, 0.68306011],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39226519, 0.60773481],\n",
       "       [0.81538462, 0.18461538],\n",
       "       [0.11904762, 0.88095238],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04225352, 0.95774648],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.41798942, 0.58201058],\n",
       "       [0.24226804, 0.75773196],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01098901, 0.98901099],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98421053, 0.01578947],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.04639175, 0.95360825],\n",
       "       [0.63793103, 0.36206897],\n",
       "       [0.94358974, 0.05641026],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90419162, 0.09580838],\n",
       "       [0.37912088, 0.62087912],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03428571, 0.96571429],\n",
       "       [0.77248677, 0.22751323],\n",
       "       [0.95431472, 0.04568528],\n",
       "       [0.93975904, 0.06024096],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03783784, 0.96216216],\n",
       "       [0.72222222, 0.27777778],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17801047, 0.82198953],\n",
       "       [0.11290323, 0.88709677],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96774194, 0.03225806],\n",
       "       [0.94413408, 0.05586592],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98170732, 0.01829268],\n",
       "       [0.91237113, 0.08762887],\n",
       "       [0.015625  , 0.984375  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05699482, 0.94300518],\n",
       "       [0.04469274, 0.95530726],\n",
       "       [0.        , 1.        ],\n",
       "       [0.61458333, 0.38541667],\n",
       "       [0.04347826, 0.95652174],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03626943, 0.96373057],\n",
       "       [0.93269231, 0.06730769],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02717391, 0.97282609],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94535519, 0.05464481],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01333333, 0.98666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90957447, 0.09042553],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96987952, 0.03012048],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97126437, 0.02873563],\n",
       "       [0.40740741, 0.59259259],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08465608, 0.91534392],\n",
       "       [0.99421965, 0.00578035],\n",
       "       [0.17934783, 0.82065217],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1396648 , 0.8603352 ],\n",
       "       [0.23529412, 0.76470588],\n",
       "       [0.734375  , 0.265625  ],\n",
       "       [0.97191011, 0.02808989],\n",
       "       [0.03825137, 0.96174863],\n",
       "       [0.96984925, 0.03015075],\n",
       "       [0.02040816, 0.97959184],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.16582915, 0.83417085],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01630435, 0.98369565],\n",
       "       [0.23463687, 0.76536313],\n",
       "       [0.96629213, 0.03370787],\n",
       "       [1.        , 0.        ],\n",
       "       [0.86458333, 0.13541667],\n",
       "       [0.98214286, 0.01785714],\n",
       "       [0.03664921, 0.96335079],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.6402439 , 0.3597561 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.57647059, 0.42352941],\n",
       "       [0.25824176, 0.74175824],\n",
       "       [0.99404762, 0.00595238],\n",
       "       [0.7027027 , 0.2972973 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
    "    n_estimators=500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876375\n",
      "sepal width (cm) 0.02311928828251033\n",
      "petal length (cm) 0.4410304643639577\n",
      "petal width (cm) 0.4233579963547682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 부스팅\n",
    "\n",
    "### 7.5.1 에이다부스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2 그레이디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=91, random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred)\n",
    "          for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.38003\n",
      "[1]\tvalidation_0-rmse:0.30196\n",
      "[2]\tvalidation_0-rmse:0.25250\n",
      "[3]\tvalidation_0-rmse:0.22243\n",
      "[4]\tvalidation_0-rmse:0.20665\n",
      "[5]\tvalidation_0-rmse:0.20167\n",
      "[6]\tvalidation_0-rmse:0.19871\n",
      "[7]\tvalidation_0-rmse:0.19543\n",
      "[8]\tvalidation_0-rmse:0.19588\n"
     ]
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
